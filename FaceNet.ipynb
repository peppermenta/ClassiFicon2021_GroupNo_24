{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "FaceNet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03fi56feQx7z",
        "outputId": "f308d213-1fe9-416c-da0e-5093d8c0c4c4"
      },
      "source": [
        "!git clone https://github.com/peppermenta/faceHack"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'faceHack' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otl96_aSRg6t",
        "outputId": "38133e9a-e4c9-447d-b779-1796f15cdf54"
      },
      "source": [
        "!pip3 install -r faceHack/requirements.txt"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r faceHack/requirements.txt (line 1)) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r faceHack/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r faceHack/requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r faceHack/requirements.txt (line 1)) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1eYcNd2SpX0"
      },
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os      \n",
        "import torchvision         \n",
        "\n",
        "class FaceDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,train=True,type='normal',transform=None):\n",
        "    super().__init__()\n",
        "    if(train):\n",
        "      self.data = np.genfromtxt(os.path.join('faceHack','dataset','train.csv'),delimiter=',',dtype=None,encoding='utf-8')\n",
        "    else:\n",
        "      self.data = np.genfromtxt(os.path.join('faceHack','dataset','test.csv'),delimiter=',',dtype=None,encoding='utf-8')\n",
        "\n",
        "    self.type=type\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_name = self.data[index][0]\n",
        "    X = Image.open(os.path.join('faceHack','dataset','happy_images','{}.jpg'.format(img_name)))\n",
        "    label = self.data[index][1]\n",
        "\n",
        "    if(self.type=='normal'):\n",
        "      if(label=='NOT smile'):\n",
        "        y = 0\n",
        "      else:\n",
        "        y = 1\n",
        "    else:\n",
        "      if(label=='positive smile'):\n",
        "        y = 1\n",
        "      else:\n",
        "        y = 0\n",
        "\n",
        "    if(self.transform):\n",
        "      X = self.transform(X)\n",
        "    return X,y\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UNCG-mETFq3"
      },
      "source": [
        "faceTransform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize(224),\n",
        "  torchvision.transforms.RandomHorizontalFlip(),\n",
        "  torchvision.transforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhLLE7c9VPwn",
        "outputId": "6b580735-9532-4b0e-f749-518d6c813f56"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "print(device)\n",
        "# model = torch.hub.load('pytorch/vision:v0.9.0', 'resnext101_32x8d', pretrained=True)\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model.layer4.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "in_features = model.fc.in_features\n",
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=in_features,out_features=128),\n",
        "    torch.nn.Linear(in_features=128,out_features=2)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "trainDataset = FaceDataset(transform=faceTransform)\n",
        "testDataset = FaceDataset(train=False,transform=faceTransform)\n",
        "trainLoader = torch.utils.data.DataLoader(trainDataset,batch_size=32,shuffle=True,num_workers=2)\n",
        "testLoader = torch.utils.data.DataLoader(testDataset,batch_size=32,shuffle=False,num_workers=2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1vNp6WBDWhIV",
        "outputId": "0b84f469-b6b7-4a8a-f70b-a8e61fb06605"
      },
      "source": [
        "model.train()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=0.0001)\n",
        "epochs = 20\n",
        "lambda1 = 0.0001\n",
        "\n",
        "loss_hist = []\n",
        "train_acc_hist = []\n",
        "test_acc_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  tot_loss = 0\n",
        "  correct = 0\n",
        "  for i,data in enumerate(trainLoader):\n",
        "    X,y = data\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    out = model(X)\n",
        "\n",
        "    _,pred = torch.max(out,dim=1)\n",
        "    correct += (pred==y).sum().item()\n",
        "\n",
        "    loss = criterion(out,y)\n",
        "    for p in model.parameters():\n",
        "      if p.requires_grad == True:\n",
        "        loss += lambda1*torch.sum(p**2)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    tot_loss += loss.item()\n",
        "    if(i%20==0):\n",
        "      print('Epoch:({},{}): Loss={}'.format(epoch,i,loss.item()))\n",
        "\n",
        "  loss_hist.append(tot_loss)\n",
        "  print('Train Accuracy is {}'.format(correct/len(trainDataset)))\n",
        "  train_acc_hist.append(correct/len(trainDataset))\n",
        "\n",
        "  test_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for X,y in testLoader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      out = model(X)\n",
        "      _,pred = torch.max(out,dim=1)\n",
        "      test_correct += (pred==y).sum().item()\n",
        "  print('Test accuracy is {}'.format(test_correct/len(testDataset)))\n",
        "  test_acc_hist.append(test_correct/len(testDataset))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([i for i in range(epochs)],loss_hist)\n",
        "plt.show()\n",
        "\n",
        "plt.plot([i for i in range(epochs)],train_acc_hist)\n",
        "plt.plot([i for i in range(epochs)],test_acc_hist)\n",
        "plt.legend(['Train Accuracy','Test Accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:(0,0): Loss=1.2052834033966064\n",
            "Epoch:(0,20): Loss=0.8940039277076721\n",
            "Epoch:(0,40): Loss=0.9091390371322632\n",
            "Epoch:(0,60): Loss=0.936480700969696\n",
            "Epoch:(0,80): Loss=0.9123072028160095\n",
            "Epoch:(0,100): Loss=0.8361541032791138\n",
            "Epoch:(0,120): Loss=0.9347668886184692\n",
            "Epoch:(0,140): Loss=0.8243680596351624\n",
            "Train Accuracy is 0.7913475470916994\n",
            "Test accuracy is 0.8100558659217877\n",
            "Epoch:(1,0): Loss=0.710847795009613\n",
            "Epoch:(1,20): Loss=0.7991715669631958\n",
            "Epoch:(1,40): Loss=0.6995925307273865\n",
            "Epoch:(1,60): Loss=0.8800614476203918\n",
            "Epoch:(1,80): Loss=0.9180770516395569\n",
            "Epoch:(1,100): Loss=0.7769805192947388\n",
            "Epoch:(1,120): Loss=0.6507053971290588\n",
            "Epoch:(1,140): Loss=0.7632126808166504\n",
            "Train Accuracy is 0.8712481887807907\n",
            "Test accuracy is 0.8417132216014898\n",
            "Epoch:(2,0): Loss=0.7876995205879211\n",
            "Epoch:(2,20): Loss=0.6300920844078064\n",
            "Epoch:(2,40): Loss=0.5786898136138916\n",
            "Epoch:(2,60): Loss=0.6473541259765625\n",
            "Epoch:(2,80): Loss=0.5775981545448303\n",
            "Epoch:(2,100): Loss=0.6960486769676208\n",
            "Epoch:(2,120): Loss=0.8439096808433533\n",
            "Epoch:(2,140): Loss=0.5495160818099976\n",
            "Train Accuracy is 0.9227903125646864\n",
            "Test accuracy is 0.8218497827436375\n",
            "Epoch:(3,0): Loss=0.512967050075531\n",
            "Epoch:(3,20): Loss=0.5762560367584229\n",
            "Epoch:(3,40): Loss=0.4896543025970459\n",
            "Epoch:(3,60): Loss=0.49974820017814636\n",
            "Epoch:(3,80): Loss=0.49866440892219543\n",
            "Epoch:(3,100): Loss=0.6520645022392273\n",
            "Epoch:(3,120): Loss=0.56205153465271\n",
            "Epoch:(3,140): Loss=0.6479564309120178\n",
            "Train Accuracy is 0.9410060028979508\n",
            "Test accuracy is 0.8441961514587213\n",
            "Epoch:(4,0): Loss=0.6209812760353088\n",
            "Epoch:(4,20): Loss=0.6957757472991943\n",
            "Epoch:(4,40): Loss=0.49535009264945984\n",
            "Epoch:(4,60): Loss=0.5230697989463806\n",
            "Epoch:(4,80): Loss=0.47896820306777954\n",
            "Epoch:(4,100): Loss=0.5432571172714233\n",
            "Epoch:(4,120): Loss=0.5890795588493347\n",
            "Epoch:(4,140): Loss=0.6053383350372314\n",
            "Train Accuracy is 0.9664665700683088\n",
            "Test accuracy is 0.8324022346368715\n",
            "Epoch:(5,0): Loss=0.45422300696372986\n",
            "Epoch:(5,20): Loss=0.4577181935310364\n",
            "Epoch:(5,40): Loss=0.47210583090782166\n",
            "Epoch:(5,60): Loss=0.4531882703304291\n",
            "Epoch:(5,80): Loss=0.581657350063324\n",
            "Epoch:(5,100): Loss=0.4998122751712799\n",
            "Epoch:(5,120): Loss=0.49596381187438965\n",
            "Epoch:(5,140): Loss=0.4761243462562561\n",
            "Train Accuracy is 0.9714344856137446\n",
            "Test accuracy is 0.8007448789571695\n",
            "Epoch:(6,0): Loss=0.5590792298316956\n",
            "Epoch:(6,20): Loss=0.4401884078979492\n",
            "Epoch:(6,40): Loss=0.7200425267219543\n",
            "Epoch:(6,60): Loss=0.4745873510837555\n",
            "Epoch:(6,80): Loss=0.48613402247428894\n",
            "Epoch:(6,100): Loss=0.4734967052936554\n",
            "Epoch:(6,120): Loss=0.5246848464012146\n",
            "Epoch:(6,140): Loss=0.5856932401657104\n",
            "Train Accuracy is 0.9780583730076589\n",
            "Test accuracy is 0.8379888268156425\n",
            "Epoch:(7,0): Loss=0.48860493302345276\n",
            "Epoch:(7,20): Loss=0.44947919249534607\n",
            "Epoch:(7,40): Loss=0.43695178627967834\n",
            "Epoch:(7,60): Loss=0.5196918249130249\n",
            "Epoch:(7,80): Loss=0.5256657004356384\n",
            "Epoch:(7,100): Loss=0.43894335627555847\n",
            "Epoch:(7,120): Loss=0.4559321105480194\n",
            "Epoch:(7,140): Loss=0.4349052906036377\n",
            "Train Accuracy is 0.9832332850341544\n",
            "Test accuracy is 0.8336436995654872\n",
            "Epoch:(8,0): Loss=0.43865135312080383\n",
            "Epoch:(8,20): Loss=0.4560845196247101\n",
            "Epoch:(8,40): Loss=0.4395585060119629\n",
            "Epoch:(8,60): Loss=0.4484415650367737\n",
            "Epoch:(8,80): Loss=0.4316864609718323\n",
            "Epoch:(8,100): Loss=0.4373456537723541\n",
            "Epoch:(8,120): Loss=0.44691988825798035\n",
            "Epoch:(8,140): Loss=0.5156463384628296\n",
            "Train Accuracy is 0.9882012005795902\n",
            "Test accuracy is 0.8280571073867163\n",
            "Epoch:(9,0): Loss=0.4276472330093384\n",
            "Epoch:(9,20): Loss=0.4639268219470978\n",
            "Epoch:(9,40): Loss=0.4288593828678131\n",
            "Epoch:(9,60): Loss=0.44009777903556824\n",
            "Epoch:(9,80): Loss=0.43761783838272095\n",
            "Epoch:(9,100): Loss=0.4351857006549835\n",
            "Epoch:(9,120): Loss=0.5158848762512207\n",
            "Epoch:(9,140): Loss=0.42690128087997437\n",
            "Train Accuracy is 0.9915131442765474\n",
            "Test accuracy is 0.8336436995654872\n",
            "Epoch:(10,0): Loss=0.456085205078125\n",
            "Epoch:(10,20): Loss=0.4287193715572357\n",
            "Epoch:(10,40): Loss=0.42596423625946045\n",
            "Epoch:(10,60): Loss=0.4206889271736145\n",
            "Epoch:(10,80): Loss=0.4337944984436035\n",
            "Epoch:(10,100): Loss=0.44723251461982727\n",
            "Epoch:(10,120): Loss=0.41921883821487427\n",
            "Epoch:(10,140): Loss=0.49196842312812805\n",
            "Train Accuracy is 0.991927137238667\n",
            "Test accuracy is 0.824332712600869\n",
            "Epoch:(11,0): Loss=0.4237174689769745\n",
            "Epoch:(11,20): Loss=0.4963691830635071\n",
            "Epoch:(11,40): Loss=0.42566657066345215\n",
            "Epoch:(11,60): Loss=0.44990047812461853\n",
            "Epoch:(11,80): Loss=0.46773669123649597\n",
            "Epoch:(11,100): Loss=0.4835888147354126\n",
            "Epoch:(11,120): Loss=0.44634586572647095\n",
            "Epoch:(11,140): Loss=0.4259604513645172\n",
            "Train Accuracy is 0.9896501759470089\n",
            "Test accuracy is 0.8324022346368715\n",
            "Epoch:(12,0): Loss=0.41582345962524414\n",
            "Epoch:(12,20): Loss=0.46059468388557434\n",
            "Epoch:(12,40): Loss=0.4221497178077698\n",
            "Epoch:(12,60): Loss=0.41582801938056946\n",
            "Epoch:(12,80): Loss=0.5722633004188538\n",
            "Epoch:(12,100): Loss=0.4312984347343445\n",
            "Epoch:(12,120): Loss=0.4138775169849396\n",
            "Epoch:(12,140): Loss=0.43293336033821106\n",
            "Train Accuracy is 0.9842682674394535\n",
            "Test accuracy is 0.8175046554934823\n",
            "Epoch:(13,0): Loss=0.46952182054519653\n",
            "Epoch:(13,20): Loss=0.4227692186832428\n",
            "Epoch:(13,40): Loss=0.4252980351448059\n",
            "Epoch:(13,60): Loss=0.41483190655708313\n",
            "Epoch:(13,80): Loss=0.4071880280971527\n",
            "Epoch:(13,100): Loss=0.4055745303630829\n",
            "Epoch:(13,120): Loss=0.4069090187549591\n",
            "Epoch:(13,140): Loss=0.4059165418148041\n",
            "Train Accuracy is 0.9892361829848892\n",
            "Test accuracy is 0.8379888268156425\n",
            "Epoch:(14,0): Loss=0.5214740037918091\n",
            "Epoch:(14,20): Loss=0.40610477328300476\n",
            "Epoch:(14,40): Loss=0.42686134576797485\n",
            "Epoch:(14,60): Loss=0.40308240056037903\n",
            "Epoch:(14,80): Loss=0.41046464443206787\n",
            "Epoch:(14,100): Loss=0.40123361349105835\n",
            "Epoch:(14,120): Loss=0.40242093801498413\n",
            "Epoch:(14,140): Loss=0.9420100450515747\n",
            "Train Accuracy is 0.990685158352308\n",
            "Test accuracy is 0.8386095592799503\n",
            "Epoch:(15,0): Loss=0.6040411591529846\n",
            "Epoch:(15,20): Loss=0.42308109998703003\n",
            "Epoch:(15,40): Loss=0.4015195667743683\n",
            "Epoch:(15,60): Loss=0.4023958146572113\n",
            "Epoch:(15,80): Loss=0.39783450961112976\n",
            "Epoch:(15,100): Loss=0.400293231010437\n",
            "Epoch:(15,120): Loss=0.40317320823669434\n",
            "Epoch:(15,140): Loss=0.39530307054519653\n",
            "Train Accuracy is 0.991927137238667\n",
            "Test accuracy is 0.8448168839230292\n",
            "Epoch:(16,0): Loss=0.40613627433776855\n",
            "Epoch:(16,20): Loss=0.3976341784000397\n",
            "Epoch:(16,40): Loss=0.39475780725479126\n",
            "Epoch:(16,60): Loss=0.415211945772171\n",
            "Epoch:(16,80): Loss=0.4339577853679657\n",
            "Epoch:(16,100): Loss=0.4042569398880005\n",
            "Epoch:(16,120): Loss=0.4201110303401947\n",
            "Epoch:(16,140): Loss=0.39168936014175415\n",
            "Train Accuracy is 0.990685158352308\n",
            "Test accuracy is 0.839851024208566\n",
            "Epoch:(17,0): Loss=0.4671347439289093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1ce2ee05c80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFvU-NWoY5-e"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}